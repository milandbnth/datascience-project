---
title: "finalproject"
author: "Milan Debnath"
date: "2022-11-30"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(tidyr)
machines <- read.csv("/Users/mdebnath/Documents/Illinois Institute of Tech/classes/Programming for Data Analytics)/Final Project/machine.csv")
```
# Introduction

> The machine dataset contains the computer hardware related information from different computer manufacturing companies. This dataset is used to predict the performance of the computers based on numerical attributes.

```{r}
head(machines)
```
## To see number of observations
```{r}

str(machines)
```

```{r }
attributes(machines)
```

## Number of observations is 209 of 10 variables

```{r}
dim(machines)
```


##mean of minimum main memory in kb
```{r }
mean(machines$mmin)
```
##mean of maximum main memory
```{r }
sd(machines$mmin)
```

```{r }
mean(machines$mmax)
```

```{r }
sd(machines$mmax)

```
##mean of published reletive perfomance
```{r }
mean(machines$prp)
```
##Histogram of machine cycle times per nanosecond

```{r }
qplot(machines$myct, bins=20)

```
## we see that there is less machines with higher cycle times as compared to those machines with low cycle times, this is expected as the general consumer of a machine doesn't need a high end machine most of the time, due to other factors like cost.


## Saving the first 20 records of the machines data set as a data frame with name Machines_A and producing a summary
```{r }
Machines_A<-as.data.frame(machines[1:20,])
summary(Machines_A)

```
##Generating a new column with min and max main memories and adding the column to the Machines_A dataframe
```{r }
MinMaxMemo<-""
MinMaxMemo[Machines_A$mmin <=33000]<- "low"
MinMaxMemo[Machines_A$mmax >33000]<- "high"
```


```{r }
Machines_New <- data.frame(Machines_A,MinMaxMemo)
head(Machines_New)
```


```{r }
ggplot(data = Machines_New, aes(x = cach)) +
  geom_histogram(aes(fill = MinMaxMemo),bins = 15,color = "black")
```

```{r }
ggplot(data = Machines_New, aes(x = cach)) +
  geom_histogram(aes(fill = MinMaxMemo),bins = 15,color = "black", position="fill")
```
##Based on the distribution, we see that most machines with high main memory also have high cache memory, Although having missing values, It is logical to conclude that that is the case.


```{r }
ggplot(data = Machines_New) +
  geom_boxplot(mapping = aes(x = reorder(MinMaxMemo,cach , FUN = median), y = cach))
```

## The overlay boxplot shows that machines with high main memory have a higher cach memory unlike those machines with low cach memory.

# Missing Values

```{r}
colSums(is.na(machines))
```

>These is no missing value

## Hypothesis Testing
**We are trying to do Hypothesis testing on  Published Relative Performance and Estimated Relative Performance, to check if there is any difference between these two features**

> We are doing EDA on the published and relative performances of all the machines.

```{r}

par(mfrow = c(2,2)) 
boxplot(machines$prp, horizontal = TRUE)
hist(machines$prp, main = "Published Relative Performance")
boxplot(machines$erp, horizontal = TRUE)
hist(machines$erp, main = "Estimated Relative Performance")
```

> We want to compare the published and relative performance of IBM machines through hypothesis testing
> We want to compare the performances of IBM machines. This can be done by performing a test of difference in means assuming the sample is approximately from a normal distribution.

```{r}
ibm_dt <- machines[machines$vend == "ibm",]
```

> We should do f-test to compare mean, as we dont know the variance. We can conduct an f-test first to see if they have same variance. NUll Hypo: **ibm_prp/ibm_erp = 1** Alt Hypo: **ibm_prp/ibm_erp ≠ 1**. Confidence interval = 95%

```{r}
var.test(ibm_dt$prp, ibm_dt$erp, conf.level = 0.95)
```
> Based on f-test we can see a < p-value. As p-value is large, we failed to reject the nul hypothesis which means there is significant evidence that the variances are equal.

> We can do t-test now to check if the mean is different. Null Hypo : **ibm_prp-ibm_erp = 0** Alt Hypo: **ibm_prp-ibm_erp ≠ 0**. Confidence interval = 95%

```{r}
t.test(ibm_dt$prp, ibm_dt$erp, var.equal = TRUE)
```
> As p-value > 0.05, we failed to reject Null Hypothesis. The published and estimated performances of ibm machines are same.

## Linear Regression

>Simple linear regression between machine cycle time and published relative performance


```{r}

fitlm <- lm(prp ~ myct, data = machines)
summary(fitlm)
```
> Prediction of erp when myct is 98.

```{r}
new <- data.frame(myct = 98)
predict(fitlm,new)
```
> Confidence interval

```{r}
predict(fitlm, new, interval = "confidence")
```
> Prediction Interval

```{r}
predict(fitlm, new, interval = "prediction")
```

> plot

```{r}
plot(machines$myct,machines$prp)
abline(fitlm, col="red")
```

> diagnostic plots

```{r}
par(mfrow=c(2,2))
plot(fitlm)
```

>Multiple Linear Regression

```{r}
mach_numeric <- subset(machines, select = -c(vend,model)) # categorical attributes dropped
#Splitting dataset
i <- sample(2, nrow(mach_numeric), replace = TRUE, prob = c(0.8,0.2))
mach_train <- mach_numeric[i==1,]
mach_test<- mach_numeric[i == 2,]

```
> Correlation

```{r}
cor(mach_train)
```

> Multiple linear regression

```{r}
fitlml <- lm(prp~., data = mach_train)
summary(fitlml)
```

> Plot

```{r}
par(mfrow = c(2,2))
plot(fitlml)
```
>Prediction

```{r}
library("Metrics")
ypredct <- predict(object = fitlml, newdata = mach_test)
summary(ypredct)
mae(mach_test$prp, ypredct)
mse(mach_test$prp, ypredct)
```

>Forward stepwise regression

```{r}
library(MASS)
# create null model
intercpt_only <- lm(prp ~ 1, data = mach_train)
#create full model
all <- lm(prp~., data = mach_train)
# perform forward stepwise regression
forwrd <- stepAIC (intercpt_only, direction = 'forward', scope = formula(all))
```

> final model

```{r}
summary(forwrd)
```

> Checking MAE and MSE

```{r}
valfrwrd <- predict(object = forwrd, newdata = mach_test)
mae(mach_test$prp, valfrwrd)
mse(mach_test$prp, valfrwrd)
```

> Backward stepwise selection

```{r}
backward <- stepAIC(all, direction = 'backward')

```

> backward summary

```{r}
summary(backward)
```

> MAE & MSE

```{r}
valbkwrd <- predict(object = backward, newdata = mach_test)
mae(mach_test$prp, valbkwrd)
mse(mach_test$prp, valbkwrd)

```


